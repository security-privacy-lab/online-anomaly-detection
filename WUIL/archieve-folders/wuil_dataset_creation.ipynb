{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going to create 3 types of the dataset: \n",
    "1. Random injection - We are going to get random indexes inside of the benign dataset and going to insert the random malicious data into there regarding the session ID (which is the timestamp in integer)\n",
    "2. 5 minute injection - We are going to find the 5 minute gap that exists in the benign dataset and going to inject the **whole** attacking dataset into the benign therefore it would have 5 minute(since one attacking dataset is 5 minute) malicious activities\n",
    "3. Organized dataset - This dataset we are going to combine the malicious dataset and benign dataset(by pandas concat method) and going to sort the dataset by the session ID therefore they are going to be organized. \n",
    "----\n",
    "\n",
    "\n",
    "## Preprocessing the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Session_ID</th>\n",
       "      <th>Depth</th>\n",
       "      <th>Path</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>40675566</td>\n",
       "      <td>4</td>\n",
       "      <td>0\\1\\2\\3\\4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>40675566</td>\n",
       "      <td>4</td>\n",
       "      <td>0\\1\\2\\3\\4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>40675566</td>\n",
       "      <td>4</td>\n",
       "      <td>0\\1\\2\\3\\4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>40675566</td>\n",
       "      <td>4</td>\n",
       "      <td>0\\1\\2\\3\\4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>40675566</td>\n",
       "      <td>4</td>\n",
       "      <td>0\\1\\2\\3\\4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21657</th>\n",
       "      <td>14908</td>\n",
       "      <td>40242060</td>\n",
       "      <td>7</td>\n",
       "      <td>0\\1\\2\\3\\180\\677\\695\\697</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21658</th>\n",
       "      <td>14909</td>\n",
       "      <td>40242060</td>\n",
       "      <td>8</td>\n",
       "      <td>0\\1\\2\\3\\180\\677\\695\\697\\698</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21659</th>\n",
       "      <td>14910</td>\n",
       "      <td>40242060</td>\n",
       "      <td>8</td>\n",
       "      <td>0\\1\\2\\3\\180\\677\\695\\697\\698</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21660</th>\n",
       "      <td>14911</td>\n",
       "      <td>40242060</td>\n",
       "      <td>9</td>\n",
       "      <td>0\\1\\2\\3\\180\\677\\695\\697\\698\\699</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21661</th>\n",
       "      <td>14912</td>\n",
       "      <td>40242060</td>\n",
       "      <td>8</td>\n",
       "      <td>0\\1\\2\\3\\180\\677\\695\\697\\698</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>21662 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          ID  Session_ID  Depth                             Path  Label\n",
       "0          0    40675566      4                        0\\1\\2\\3\\4      1\n",
       "1          1    40675566      4                        0\\1\\2\\3\\4      1\n",
       "2          2    40675566      4                        0\\1\\2\\3\\4      1\n",
       "3          3    40675566      4                        0\\1\\2\\3\\4      1\n",
       "4          4    40675566      4                        0\\1\\2\\3\\4      1\n",
       "...      ...         ...    ...                              ...    ...\n",
       "21657  14908    40242060      7          0\\1\\2\\3\\180\\677\\695\\697      1\n",
       "21658  14909    40242060      8      0\\1\\2\\3\\180\\677\\695\\697\\698      1\n",
       "21659  14910    40242060      8      0\\1\\2\\3\\180\\677\\695\\697\\698      1\n",
       "21660  14911    40242060      9  0\\1\\2\\3\\180\\677\\695\\697\\698\\699      1\n",
       "21661  14912    40242060      8      0\\1\\2\\3\\180\\677\\695\\697\\698      1\n",
       "\n",
       "[21662 rows x 5 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columns = ['ID', 'Date', 'Time', 'Session_ID', 'Depth', 'Path', 'Label'] # Set the names for each columns\n",
    "dataset_benign = pd.read_csv(\"user1_log.txt\", sep='|', header = None, names = columns ) # Read the datasets --> Change this line as needed depending on the name of the dataset \n",
    "dataset_benign.drop(['Date','Time'], axis = 1, inplace = True) # Drop the date and time since we are going to use session_ID column for the time\n",
    "dataset_benign = dataset_benign.sort_values(by = 'Session_ID').reset_index(drop = True)\n",
    "dataset_benign['Label'] = 0\n",
    "\n",
    "## same for these lines, change the names if needed. \n",
    "\n",
    "malicious_logs1 = pd.read_csv('Attack1_log.txt', sep='|', header=None, names=columns)\n",
    "malicious_logs2 = pd.read_csv('Attack2_log.txt', sep='|', header=None, names=columns)\n",
    "malicious_logs3 = pd.read_csv('Attack3_log.txt', sep='|', header=None, names=columns)\n",
    "malicious_logs1['Label'] = 1\n",
    "malicious_logs2['Label'] = 1\n",
    "malicious_logs3['Label'] = 1\n",
    "\n",
    "combined_malicious_logs = pd.concat([malicious_logs1, malicious_logs2, malicious_logs3], ignore_index= True)\n",
    "combined_malicious_logs['Label'] = 1\n",
    "combined_malicious_logs.drop(['Date','Time'], axis = 1, inplace = True)\n",
    "combined_malicious_logs\n",
    "\n",
    "combined_malicious_logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5-Minute Injection ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Select a gap index from Index([0, 3], dtype='int64'):  0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Date</th>\n",
       "      <th>Time</th>\n",
       "      <th>Session_ID</th>\n",
       "      <th>Depth</th>\n",
       "      <th>Path</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>302</td>\n",
       "      <td>4</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>303</td>\n",
       "      <td>4</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>603</td>\n",
       "      <td>4</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>904</td>\n",
       "      <td>4</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  ID Date Time Session_ID Depth Path Label\n",
       "0                       1     4          0\n",
       "1                       2     4          1\n",
       "2                       4     4          1\n",
       "3                     302     4          0\n",
       "4                     303     4          0\n",
       "5                     603     4          0\n",
       "6                     904     4          0"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def five_minute_injection(benign, attacker, key):\n",
    "    injected_dataset = benign.copy()\n",
    "    difference = pd.DataFrame([], columns= [\"time_diff\"])\n",
    "    difference['time_diff'] = benign[key].astype(int).shift(-1) - benign[key].astype(int)\n",
    "    gaps = difference[difference['time_diff'] >= 301]\n",
    "    try:\n",
    "        # random_gap = int(random.choice(gaps.index)) replace with this for random\n",
    "        random_gap = int(input(f\"Select a gap index from {gaps.index}: \"))\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {str(e)}\")\n",
    "        \n",
    "\n",
    "    attacker[key] = attacker[key].astype(int) - int(attacker.loc[0, key]) + 1 + int(injected_dataset.loc[random_gap, key])\n",
    "\n",
    "    injected_dataset = pd.concat([\n",
    "        injected_dataset.iloc[:random_gap+1],  \n",
    "        attacker,                      \n",
    "        injected_dataset.iloc[random_gap+1:]  \n",
    "    ]).reset_index(drop=True)\n",
    "    return injected_dataset\n",
    "\n",
    "# Quick sanity test for the function\n",
    "sample_benign = pd.DataFrame([{'ID': \"\", 'Date': \"\", 'Time': \"\", 'Session_ID': \"1\", 'Depth': \"4\", 'Path': \"\", 'Label': \"0\"}, \n",
    "                              {'ID': \"\", 'Date': \"\", 'Time': \"\", 'Session_ID': \"302\", 'Depth': \"4\", 'Path': \"\", 'Label': \"0\"},\n",
    "                              {'ID': \"\", 'Date': \"\", 'Time': \"\", 'Session_ID': \"303\", 'Depth': \"4\", 'Path': \"\", 'Label': \"0\"},\n",
    "                              {'ID': \"\", 'Date': \"\", 'Time': \"\", 'Session_ID': \"603\", 'Depth': \"4\", 'Path': \"\", 'Label': \"0\"},\n",
    "                              {'ID': \"\", 'Date': \"\", 'Time': \"\", 'Session_ID': \"904\", 'Depth': \"4\", 'Path': \"\", 'Label': \"0\"}])\n",
    "sample_attacker = pd.DataFrame([{'ID': \"\", 'Date': \"\", 'Time': \"\", 'Session_ID': \"1\", 'Depth': \"4\", 'Path': \"\", 'Label': \"1\"}, {'ID': \"\", 'Date': \"\", 'Time': \"\", 'Session_ID': \"3\", 'Depth': \"4\", 'Path': \"\", 'Label': \"1\"}])\n",
    "\n",
    "sample_injected_df = five_minute_injection(sample_benign, sample_attacker, \"Session_ID\")\n",
    "sample_injected_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sedanspot\n",
    "Start generating the Sedanspot dataset which is in format of **Timestamp, source, Destination, weight and label**\n",
    "\n",
    "Lets work on the first type of the dataset which is having random indexes and inserting malicious dataset into the benign "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dataset_benign' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[26], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m injected_dataset \u001b[38;5;241m=\u001b[39m dataset_benign\u001b[38;5;241m.\u001b[39mcopy() \u001b[38;5;66;03m# We copy the benign dataset therefore we don't have to import the benign dataset everytime when we work on it\u001b[39;00m\n\u001b[1;32m      2\u001b[0m injected_indices \u001b[38;5;241m=\u001b[39m [] \u001b[38;5;66;03m# this is for checking if the dataset really have been randomly inserted\u001b[39;00m\n\u001b[1;32m      3\u001b[0m f \u001b[38;5;241m=\u001b[39m combined_malicious_logs \u001b[38;5;66;03m# Which dataset we are going to insert. We adjust this line for changing which file we are trying to insert\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'dataset_benign' is not defined"
     ]
    }
   ],
   "source": [
    "injected_dataset = dataset_benign.copy() # We copy the benign dataset therefore we don't have to import the benign dataset everytime when we work on it\n",
    "injected_indices = [] # this is for checking if the dataset really have been randomly inserted\n",
    "f = combined_malicious_logs # Which dataset we are going to insert. We adjust this line for changing which file we are trying to insert\n",
    "for _, malicious_row in f.iterrows(): # We read the malicious dataset here\n",
    "        malicious_data = {\n",
    "                'Session_ID': malicious_row['Session_ID'],\n",
    "                'Depth': malicious_row['Depth'],\n",
    "                'Path': malicious_row['Path'],\n",
    "                'Label': malicious_row['Label']\n",
    "    }\n",
    "        malicious_row_df = pd.DataFrame([malicious_data])\n",
    "        \n",
    "        random_index = random.randint(0, len(injected_dataset)) # To make sure that the malicious are being injected to random index \n",
    "        injected_indices.append(random_index)\n",
    "        injected_dataset = pd.concat([\n",
    "                injected_dataset.iloc[:random_index],  \n",
    "                malicious_row_df,                      \n",
    "                injected_dataset.iloc[random_index:]  \n",
    "        ]).reset_index(drop=True)\n",
    "\n",
    "print(f\"Injected {len(f)} malicious rows into the benign dataset.\")\n",
    "print(f\"Original benign dataset length: {len(dataset_benign)}\")\n",
    "print(f\"Injected dataset length: {len(injected_dataset)}\")\n",
    "print(injected_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edges = []\n",
    "prev_path = None\n",
    "\n",
    "for _, row in injected_dataset.iterrows():\n",
    "    current_path = row['Path']\n",
    "    timestamp = row['Session_ID']\n",
    "    label = row['Label']\n",
    "\n",
    "    # Self-edge\n",
    "    if prev_path == current_path:\n",
    "        edges.append({\n",
    "            'src_node' : current_path,\n",
    "            'dst_node': current_path,\n",
    "            'timestamp' : timestamp,\n",
    "            'weight' : 1,\n",
    "            'label' : label\n",
    "            \n",
    "        })\n",
    "    elif prev_path is not None:\n",
    "        edges.append({      \n",
    "            'src_node' : prev_path,\n",
    "            'dst_node': current_path,\n",
    "            'timestamp' : row['Session_ID'],\n",
    "            'weight' : 1, # Keeps the weight as 1 as default \n",
    "            'label' : label\n",
    "        })\n",
    "    prev_path = current_path\n",
    "\n",
    "edges_df = pd.DataFrame(edges)\n",
    "edges_df[['timestamp','src_node', 'dst_node',  'weight', 'label']].to_csv(\n",
    "    'random_combined.csv', sep = ',', header = False, index = False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Work on the 5 minute gaps as we start by finding the 5 minute gaps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Session_ID  time_diff\n",
      "862       35414007     4035.0\n",
      "2092      35482614    51278.0\n",
      "3164      35504865     4653.0\n",
      "4049      35568126    49681.0\n",
      "6403      35655762    50812.0\n",
      "...            ...        ...\n",
      "257213    40319583   176128.0\n",
      "260670    40404232    48167.0\n",
      "262195    40422830     3068.0\n",
      "266526    40491750    49672.0\n",
      "271546    40574674    48456.0\n",
      "\n",
      "[80 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "dataset_benign['time_diff'] = dataset_benign['Session_ID'].diff()\n",
    "dataset_benign = dataset_benign.sort_values(by = \"Session_ID\", ascending= True)\n",
    "gaps = dataset_benign[dataset_benign['time_diff'] >= 3000]\n",
    "print(gaps[['Session_ID', 'time_diff']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "injected_dataset = dataset_benign.copy()\n",
    "injected_dataset = pd.concat([injected_dataset.iloc[:862], # We insert the malicious_logs1 into the gap \n",
    "                    malicious_logs1,\n",
    "                    injected_dataset.iloc[862:]])\n",
    "print(len(injected_dataset))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Organized version by session ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "injected_dataset = dataset_benign.copy()\n",
    "injected_dataset = pd.concat((injected_dataset, combined_malicious_logs),ignore_index= True)\n",
    "injected_dataset = injected_dataset.sort_values(by=\"Session_ID\", ascending=True)\n",
    "injected_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Code for converting the formatted data into the graph that self-edges and into csv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edges = []\n",
    "prev_path = None\n",
    "edge_weights = {}  \n",
    "for _, row in injected_dataset.iterrows():\n",
    "    current_path = row['Path']\n",
    "    timestamp = row['Session_ID']\n",
    "    label = row['Label']\n",
    "\n",
    "    # Self-edge\n",
    "    if prev_path == current_path:\n",
    "        edge_key = (current_path, current_path)  \n",
    "    elif prev_path is not None:\n",
    "        edge_key = (prev_path, current_path)  \n",
    "    else:\n",
    "        prev_path = current_path\n",
    "        continue  \n",
    "\n",
    "\n",
    "    if edge_key in edge_weights:\n",
    "        edge_weights[edge_key] += 1\n",
    "    else:\n",
    "        edge_weights[edge_key] = 1\n",
    "\n",
    "    edges.append({\n",
    "        'src_node': edge_key[0],\n",
    "        'dst_node': edge_key[1],\n",
    "        'timestamp': timestamp,\n",
    "        'weight': edge_weights[edge_key], # Increment the weight as the same node appears \n",
    "        'label': label\n",
    "    })\n",
    "\n",
    "    prev_path = current_path  \n",
    "\n",
    "\n",
    "edges_df = pd.DataFrame(edges)\n",
    "edges_df\n",
    "edges_df[['timestamp', 'src_node', 'dst_node', 'weight', 'label']].to_csv(\n",
    "    'random_attack3_with.csv', sep = ',', header = False, index = False\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Anomrank ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "injected_dataset = dataset_benign.copy() # We copy the benign dataset therefore we don't have to import the benign dataset everytime when we work on it\n",
    "injected_indices = [] # this is for checking if the dataset really have been randomly inserted\n",
    "f = combined_malicious_logs # Which dataset we are going to insert. We adjust this line for changing which file we are trying to insert\n",
    "for _, malicious_row in f.iterrows(): # We read the malicious dataset here\n",
    "        malicious_data = {\n",
    "                'Session_ID': malicious_row['Session_ID'],\n",
    "                'Depth': malicious_row['Depth'],\n",
    "                'Path': malicious_row['Path'],\n",
    "                'Label': malicious_row['Label']\n",
    "    }\n",
    "        malicious_row_df = pd.DataFrame([malicious_data])\n",
    "        \n",
    "        random_index = random.randint(0, len(injected_dataset)) # To make sure that the malicious are being injected to random index \n",
    "        injected_indices.append(random_index)\n",
    "        injected_dataset = pd.concat([\n",
    "                injected_dataset.iloc[:random_index],  \n",
    "                malicious_row_df,                      \n",
    "                injected_dataset.iloc[random_index:]  \n",
    "        ]).reset_index(drop=True)\n",
    "\n",
    "print(f\"Injected {len(f)} malicious rows into the benign dataset.\")\n",
    "print(f\"Original benign dataset length: {len(dataset_benign)}\")\n",
    "print(f\"Injected dataset length: {len(injected_dataset)}\")\n",
    "print(injected_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "injected_dataset = dataset_benign.copy()\n",
    "injected_dataset = pd.concat([injected_dataset.iloc[:862],\n",
    "                    combined_malicious_logs,\n",
    "                    injected_dataset.iloc[862:]])\n",
    "print(len(injected_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "injected_dataset = dataset_benign.copy()\n",
    "injected_dataset = pd.concat((injected_dataset, combined_malicious_logs))\n",
    "injected_dataset = injected_dataset.sort_values(by = \"Session_ID\", ascending= True )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import hashlib \n",
    "\n",
    "edges = []\n",
    "prev_path = None\n",
    "\n",
    "for _, row in injected_dataset.iterrows():\n",
    "    current_path = row['Path']\n",
    "    timestamp = row['Session_ID']\n",
    "    label = row['Label']\n",
    "    current_path_hashed = int(hashlib.md5(current_path.encode()).hexdigest(), 16) % (10**8)\n",
    "\n",
    "    # Self-edge\n",
    "    if prev_path == current_path:\n",
    "        edges.append({\n",
    "            'src_node' : current_path_hashed,\n",
    "            'dst_node': current_path_hashed,\n",
    "            'timestamp' : timestamp,\n",
    "            'label' : label\n",
    "            \n",
    "        })\n",
    "    elif prev_path is not None:\n",
    "        prev_path_hashed = int(hashlib.md5(prev_path.encode()).hexdigest(), 16) % (10**8)\n",
    "        edges.append({      \n",
    "            'src_node' : prev_path_hashed,\n",
    "            'dst_node': current_path_hashed,\n",
    "            'timestamp' : row['Session_ID'],\n",
    "            'label' : label\n",
    "        })\n",
    "    prev_path = current_path\n",
    "\n",
    "edges_df = pd.DataFrame(edges)\n",
    "edges_df[['timestamp','src_node', 'dst_node', 'label']].to_csv(\n",
    "    'organized_combined.txt', sep = ' ', header = False, index = False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MAD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MIDAS ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>src</th>\n",
       "      <th>dst</th>\n",
       "      <th>weight</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>35396524</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>35396524</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>35396524</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>35396524</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>35396524</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>274047</th>\n",
       "      <td>40617974</td>\n",
       "      <td>8538</td>\n",
       "      <td>8539</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>274048</th>\n",
       "      <td>40617974</td>\n",
       "      <td>8539</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>274049</th>\n",
       "      <td>40617974</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>274050</th>\n",
       "      <td>40617974</td>\n",
       "      <td>1</td>\n",
       "      <td>8539</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>274051</th>\n",
       "      <td>40618023</td>\n",
       "      <td>8539</td>\n",
       "      <td>212</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>274051 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        timestamp   src   dst  weight  label\n",
       "1        35396524     0     0       1      0\n",
       "2        35396524     0     0       1      0\n",
       "3        35396524     0     0       1      0\n",
       "4        35396524     0     0       1      0\n",
       "5        35396524     0     0       1      0\n",
       "...           ...   ...   ...     ...    ...\n",
       "274047   40617974  8538  8539       1      0\n",
       "274048   40617974  8539     1       1      0\n",
       "274049   40617974     1     1       1      0\n",
       "274050   40617974     1  8539       1      0\n",
       "274051   40618023  8539   212       1      0\n",
       "\n",
       "[274051 rows x 5 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def preprocess_wuil(wuil_df):\n",
    "    \n",
    "    # Select specific columns\n",
    "    df = wuil_df[[\"Session_ID\", \"Path\", \"Label\"]].copy()\n",
    "    \n",
    "    # Rename columns\n",
    "    df.rename(columns={\"Session_ID\": \"timestamp\", \"Path\": \"dst\", \"Label\": \"label\"}, inplace=True)\n",
    "\n",
    "    # Give each path a unique ID\n",
    "    df['dst'] = pd.factorize(df['dst'])[0]\n",
    "\n",
    "    # Add the 'src' column with shifted 'dst' values\n",
    "    df.insert(1, \"src\", df[\"dst\"].shift(1).fillna(-1).astype(int), allow_duplicates=False)\n",
    "    \n",
    "    # Drop the first row (row index 0) with NaN caused by the shift\n",
    "    df = df.drop(0)\n",
    "    \n",
    "    # Insert the 'weight' column at the 4th position (index 3)\n",
    "    df.insert(3, \"weight\", 1, allow_duplicates=False)\n",
    "\n",
    "    return df\n",
    "\n",
    "preprocess_wuil(dataset_benign)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>35396524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>35396524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>35396524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>35396524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>35396524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>35396525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>35396526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>35396527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>35396528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>35396529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>35396529</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   timestamp\n",
       "0   35396524\n",
       "1   35396524\n",
       "2   35396524\n",
       "3   35396524\n",
       "4   35396524\n",
       "5   35396525\n",
       "6   35396526\n",
       "7   35396527\n",
       "8   35396528\n",
       "9   35396529\n",
       "10  35396529"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def fill_gaps(wuil_df, key):\n",
    "    wuil_df = wuil_df.copy()\n",
    "    time_difference = wuil_df[key].astype(int).shift(-1) - wuil_df[key].astype(int)\n",
    "    critical_indices = wuil_df[time_difference > 1].index.tolist()\n",
    "\n",
    "    while critical_indices:\n",
    "        cur_index = critical_indices.pop(0)\n",
    "        gap = int(wuil_df.loc[cur_index+1, key]) - int(wuil_df.loc[cur_index, key])-1\n",
    "        filler = pd.DataFrame([wuil_df.iloc[cur_index]]* gap)\n",
    "        \n",
    "        filler[key] = range(int(wuil_df.loc[cur_index, key]) + 1, int(wuil_df.loc[cur_index, key]) + gap + 1)\n",
    "        wuil_df = pd.concat([\n",
    "            wuil_df.iloc[:cur_index+1],  \n",
    "            filler,                      \n",
    "            wuil_df.iloc[cur_index+1:]  \n",
    "        ]).reset_index(drop=True)\n",
    "        critical_indices = [i+gap for i in critical_indices]\n",
    "    return wuil_df\n",
    "\n",
    "\n",
    "# For sanity check, let's test this function\n",
    "sample_df_with_gaps = pd.DataFrame([{\"timestamp\": \"35396524\"}, {\"timestamp\": \"35396524\"}, {\"timestamp\": \"35396524\"}, {\"timestamp\": \"35396524\"}, {\"timestamp\": \"35396524\"}, {\"timestamp\": \"35396529\"}, {\"timestamp\": \"35396529\"}])\n",
    "fill_gaps(sample_df_with_gaps, \"timestamp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Select a gap index from Index([   264,    292,    302,    503,    521,    540,    555,    562,    634,\n",
      "          641,\n",
      "       ...\n",
      "       273804, 273925, 273935, 273944, 273962, 273971, 273989, 273995, 274032,\n",
      "       274041],\n",
      "      dtype='int64', length=1228):  10541\n"
     ]
    }
   ],
   "source": [
    "midas_dataset = five_minute_injection(dataset_benign, malicious_logs1, \"Session_ID\")\n",
    "# midas_dataset = five_minute_injection(dataset_benign, malicious_logs2, \"Session_ID\")\n",
    "# midas_dataset = five_minute_injection(dataset_benign, malicious_logs3, \"Session_ID\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "# midas_dataset = fill_gaps(midas_dataset, \"Session_ID\")\n",
    "midas_dataset = preprocess_wuil(midas_dataset).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "midas_features = midas_dataset[[\"src\", \"dst\", \"timestamp\"]].copy()\n",
    "midas_features[\"timestamp\"] = midas_features[\"timestamp\"].astype(int) - midas_features.loc[0, \"timestamp\"].astype(int) + 1\n",
    "midas_features.to_csv(\"midas_wuil_features.csv\", index=False, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "midas_dataset[[\"label\"]].to_csv(\"midas_wuil_labels.csv\", index=False, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"midas_wuil_shape.txt\", \"w\") as f:\n",
    "    f.write(f\"{midas_dataset.shape[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
